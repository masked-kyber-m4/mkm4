#include "masked-comparison.h"
#include "randombytes.h"
#include "a2b.h"
#include "transformpower2.h"
#include "a2a.h"

extern int16_t sub_mod(int16_t a, int16_t b);
extern int16_t add_mod(int16_t a, int16_t b);

static const int16_t S4[] = {3225, 105, 313, 521, 729, 937, 1145, 1353, 1561, 1769, 1977, 2185, 2393, 2601, 2809, 3017};
static const int16_t S10[] = {3328, 2, 5, 9, 12, 15, 18, 22, 25, 28, 31, 35, 38, 41, 44, 48, 
51, 54, 57, 61, 64, 67, 70, 74, 77, 80, 83, 87, 90, 93, 96, 100, 
103, 106, 109, 113, 116, 119, 122, 126, 129, 132, 135, 139, 142, 145, 148, 152, 
155, 158, 161, 165, 168, 171, 174, 178, 181, 184, 187, 191, 194, 197, 200, 204, 
207, 210, 213, 217, 220, 223, 226, 230, 233, 236, 239, 243, 246, 249, 252, 256, 
259, 262, 265, 269, 272, 275, 278, 282, 285, 288, 291, 295, 298, 301, 304, 308, 
311, 314, 317, 321, 324, 327, 330, 334, 337, 340, 343, 347, 350, 353, 356, 360, 
363, 366, 369, 373, 376, 379, 382, 386, 389, 392, 395, 399, 402, 405, 408, 412, 
415, 418, 422, 425, 428, 431, 435, 438, 441, 444, 448, 451, 454, 457, 461, 464, 
467, 470, 474, 477, 480, 483, 487, 490, 493, 496, 500, 503, 506, 509, 513, 516, 
519, 522, 526, 529, 532, 535, 539, 542, 545, 548, 552, 555, 558, 561, 565, 568, 
571, 574, 578, 581, 584, 587, 591, 594, 597, 600, 604, 607, 610, 613, 617, 620, 
623, 626, 630, 633, 636, 639, 643, 646, 649, 652, 656, 659, 662, 665, 669, 672, 
675, 678, 682, 685, 688, 691, 695, 698, 701, 704, 708, 711, 714, 717, 721, 724, 
727, 730, 734, 737, 740, 743, 747, 750, 753, 756, 760, 763, 766, 769, 773, 776, 
779, 782, 786, 789, 792, 795, 799, 802, 805, 808, 812, 815, 818, 821, 825, 828, 
831, 834, 838, 841, 844, 847, 851, 854, 857, 860, 864, 867, 870, 873, 877, 880, 
883, 886, 890, 893, 896, 899, 903, 906, 909, 912, 916, 919, 922, 925, 929, 932, 
935, 938, 942, 945, 948, 951, 955, 958, 961, 964, 968, 971, 974, 977, 981, 984, 
987, 990, 994, 997, 1000, 1003, 1007, 1010, 1013, 1016, 1020, 1023, 1026, 1029, 1033, 1036, 
1039, 1042, 1046, 1049, 1052, 1055, 1059, 1062, 1065, 1068, 1072, 1075, 1078, 1081, 1085, 1088, 
1091, 1094, 1098, 1101, 1104, 1107, 1111, 1114, 1117, 1120, 1124, 1127, 1130, 1133, 1137, 1140, 
1143, 1146, 1150, 1153, 1156, 1159, 1163, 1166, 1169, 1172, 1176, 1179, 1182, 1185, 1189, 1192, 
1195, 1198, 1202, 1205, 1208, 1211, 1215, 1218, 1221, 1224, 1228, 1231, 1234, 1237, 1241, 1244, 
1247, 1251, 1254, 1257, 1260, 1264, 1267, 1270, 1273, 1277, 1280, 1283, 1286, 1290, 1293, 1296, 
1299, 1303, 1306, 1309, 1312, 1316, 1319, 1322, 1325, 1329, 1332, 1335, 1338, 1342, 1345, 1348, 
1351, 1355, 1358, 1361, 1364, 1368, 1371, 1374, 1377, 1381, 1384, 1387, 1390, 1394, 1397, 1400, 
1403, 1407, 1410, 1413, 1416, 1420, 1423, 1426, 1429, 1433, 1436, 1439, 1442, 1446, 1449, 1452, 
1455, 1459, 1462, 1465, 1468, 1472, 1475, 1478, 1481, 1485, 1488, 1491, 1494, 1498, 1501, 1504, 
1507, 1511, 1514, 1517, 1520, 1524, 1527, 1530, 1533, 1537, 1540, 1543, 1546, 1550, 1553, 1556, 
1559, 1563, 1566, 1569, 1572, 1576, 1579, 1582, 1585, 1589, 1592, 1595, 1598, 1602, 1605, 1608, 
1611, 1615, 1618, 1621, 1624, 1628, 1631, 1634, 1637, 1641, 1644, 1647, 1650, 1654, 1657, 1660, 
1663, 1667, 1670, 1673, 1676, 1680, 1683, 1686, 1689, 1693, 1696, 1699, 1702, 1706, 1709, 1712, 
1715, 1719, 1722, 1725, 1728, 1732, 1735, 1738, 1741, 1745, 1748, 1751, 1754, 1758, 1761, 1764, 
1767, 1771, 1774, 1777, 1780, 1784, 1787, 1790, 1793, 1797, 1800, 1803, 1806, 1810, 1813, 1816, 
1819, 1823, 1826, 1829, 1832, 1836, 1839, 1842, 1845, 1849, 1852, 1855, 1858, 1862, 1865, 1868, 
1871, 1875, 1878, 1881, 1884, 1888, 1891, 1894, 1897, 1901, 1904, 1907, 1910, 1914, 1917, 1920, 
1923, 1927, 1930, 1933, 1936, 1940, 1943, 1946, 1949, 1953, 1956, 1959, 1962, 1966, 1969, 1972, 
1975, 1979, 1982, 1985, 1988, 1992, 1995, 1998, 2001, 2005, 2008, 2011, 2014, 2018, 2021, 2024, 
2027, 2031, 2034, 2037, 2040, 2044, 2047, 2050, 2053, 2057, 2060, 2063, 2066, 2070, 2073, 2076, 
2079, 2083, 2086, 2089, 2093, 2096, 2099, 2102, 2106, 2109, 2112, 2115, 2119, 2122, 2125, 2128, 
2132, 2135, 2138, 2141, 2145, 2148, 2151, 2154, 2158, 2161, 2164, 2167, 2171, 2174, 2177, 2180, 
2184, 2187, 2190, 2193, 2197, 2200, 2203, 2206, 2210, 2213, 2216, 2219, 2223, 2226, 2229, 2232, 
2236, 2239, 2242, 2245, 2249, 2252, 2255, 2258, 2262, 2265, 2268, 2271, 2275, 2278, 2281, 2284, 
2288, 2291, 2294, 2297, 2301, 2304, 2307, 2310, 2314, 2317, 2320, 2323, 2327, 2330, 2333, 2336, 
2340, 2343, 2346, 2349, 2353, 2356, 2359, 2362, 2366, 2369, 2372, 2375, 2379, 2382, 2385, 2388, 
2392, 2395, 2398, 2401, 2405, 2408, 2411, 2414, 2418, 2421, 2424, 2427, 2431, 2434, 2437, 2440, 
2444, 2447, 2450, 2453, 2457, 2460, 2463, 2466, 2470, 2473, 2476, 2479, 2483, 2486, 2489, 2492, 
2496, 2499, 2502, 2505, 2509, 2512, 2515, 2518, 2522, 2525, 2528, 2531, 2535, 2538, 2541, 2544, 
2548, 2551, 2554, 2557, 2561, 2564, 2567, 2570, 2574, 2577, 2580, 2583, 2587, 2590, 2593, 2596, 
2600, 2603, 2606, 2609, 2613, 2616, 2619, 2622, 2626, 2629, 2632, 2635, 2639, 2642, 2645, 2648, 
2652, 2655, 2658, 2661, 2665, 2668, 2671, 2674, 2678, 2681, 2684, 2687, 2691, 2694, 2697, 2700, 
2704, 2707, 2710, 2713, 2717, 2720, 2723, 2726, 2730, 2733, 2736, 2739, 2743, 2746, 2749, 2752, 
2756, 2759, 2762, 2765, 2769, 2772, 2775, 2778, 2782, 2785, 2788, 2791, 2795, 2798, 2801, 2804, 
2808, 2811, 2814, 2817, 2821, 2824, 2827, 2830, 2834, 2837, 2840, 2843, 2847, 2850, 2853, 2856, 
2860, 2863, 2866, 2869, 2873, 2876, 2879, 2882, 2886, 2889, 2892, 2895, 2899, 2902, 2905, 2908, 
2912, 2915, 2918, 2922, 2925, 2928, 2931, 2935, 2938, 2941, 2944, 2948, 2951, 2954, 2957, 2961, 
2964, 2967, 2970, 2974, 2977, 2980, 2983, 2987, 2990, 2993, 2996, 3000, 3003, 3006, 3009, 3013, 
3016, 3019, 3022, 3026, 3029, 3032, 3035, 3039, 3042, 3045, 3048, 3052, 3055, 3058, 3061, 3065, 
3068, 3071, 3074, 3078, 3081, 3084, 3087, 3091, 3094, 3097, 3100, 3104, 3107, 3110, 3113, 3117, 
3120, 3123, 3126, 3130, 3133, 3136, 3139, 3143, 3146, 3149, 3152, 3156, 3159, 3162, 3165, 3169, 
3172, 3175, 3178, 3182, 3185, 3188, 3191, 3195, 3198, 3201, 3204, 3208, 3211, 3214, 3217, 3221, 
3224, 3227, 3230, 3234, 3237, 3240, 3243, 3247, 3250, 3253, 3256, 3260, 3263, 3266, 3269, 3273, 
3276, 3279, 3282, 3286, 3289, 3292, 3295, 3299, 3302, 3305, 3308, 3312, 3315, 3318, 3321, 3325};

/*************************************************
* Name:        secand
*
* Description: Compute masked and of x and y, [Alg. 18, SPOG19]
*
* Arguments:   - masked_u32 x: masked input bitslice
*              - masked_u32 y: masked input bitslice
**************************************************/
static masked_u32 secand(masked_u32 x, masked_u32 y)
{
  int i,j;
  masked_u32 z;
  uint32_t r[MASKING_N][MASKING_N];
  for (i = 0; i < MASKING_N; i++)
    z.u32[i] = x.u32[i] & y.u32[i];
  
  for (i = 0; i < MASKING_N-1; i++)
  {
    for (j = i+1; j < MASKING_N; j++)
    {
      r[i][j] = randomint();
      r[j][i] = r[i][j] ^ (x.u32[i] & y.u32[j]) ^ (x.u32[j] & y.u32[i]);
      z.u32[i] ^= r[i][j];
      z.u32[j] ^= r[j][i];
    }
  }
  return z;
}

/*************************************************
* Name:        polyvec_poly_unpack
*
* Description: Deserialization of a polynomial of a polyvec,
*              Used to unpack a polyvec one poly at a time in a loop.
*
* Arguments:   - const poly *r:     pointer to output polynomial
*              - unsigned char *a:  pointer to input byte string representation of a polyvec (of length KYBER_POLYVECCOMPRESSEDBYTES)
*              - int i:             index of poly in polyvec to decompress
**************************************************/
static void polyvec_poly_unpack(poly *r, const unsigned char *a, int i) {
  int j;
#if (KYBER_POLYVECCOMPRESSEDBYTES == (KYBER_K * 352))
    for(j=0;j<KYBER_N/8;j++)
    {
      r->coeffs[8*j+0] =  (((a[352*i+11*j+ 0]       | (((uint32_t)a[352*i+11*j+ 1] & 0x07) << 8))));
      r->coeffs[8*j+1] = ((((a[352*i+11*j+ 1] >> 3) | (((uint32_t)a[352*i+11*j+ 2] & 0x3f) << 5))));
      r->coeffs[8*j+2] = ((((a[352*i+11*j+ 2] >> 6) | (((uint32_t)a[352*i+11*j+ 3] & 0xff) << 2) | (((uint32_t)a[352*i+11*j+4] & 0x01) << 10))));
      r->coeffs[8*j+3] = ((((a[352*i+11*j+ 4] >> 1) | (((uint32_t)a[352*i+11*j+ 5] & 0x0f) << 7))));
      r->coeffs[8*j+4] = ((((a[352*i+11*j+ 5] >> 4) | (((uint32_t)a[352*i+11*j+ 6] & 0x7f) << 4))));
      r->coeffs[8*j+5] = ((((a[352*i+11*j+ 6] >> 7) | (((uint32_t)a[352*i+11*j+ 7] & 0xff) << 1) | (((uint32_t)a[352*i+11*j+8] & 0x03) <<  9))));
      r->coeffs[8*j+6] = ((((a[352*i+11*j+ 8] >> 2) | (((uint32_t)a[352*i+11*j+ 9] & 0x1f) << 6))));
      r->coeffs[8*j+7] = ((((a[352*i+11*j+ 9] >> 5) | (((uint32_t)a[352*i+11*j+10] & 0xff) << 3))));
    }
#elif (KYBER_POLYVECCOMPRESSEDBYTES == (KYBER_K * 320))
    for(j=0;j<KYBER_N/4;j++)
    {
      r->coeffs[4*j+0] =  (((a[320*i+5*j+ 0]       | (((uint32_t)a[320*i+5*j+ 1] & 0x03) << 8))));
      r->coeffs[4*j+1] = ((((a[320*i+5*j+ 1] >> 2) | (((uint32_t)a[320*i+5*j+ 2] & 0x0f) << 6))));
      r->coeffs[4*j+2] = ((((a[320*i+5*j+ 2] >> 4) | (((uint32_t)a[320*i+5*j+ 3] & 0x3f) << 4))));
      r->coeffs[4*j+3] = ((((a[320*i+5*j+ 3] >> 6) | (((uint32_t)a[320*i+5*j+ 4] & 0xff) << 2))));
    }
#else
#error "KYBER_POLYVECCOMPRESSEDBYTES needs to be in {320*KYBER_K, 352*KYBER_K}"
#endif
}

/*************************************************
* Name:        poly_unpack
*
* Description: De-serialization of a polynomial
*
* Arguments:   - poly *r:                pointer to output polynomial
*              - const unsigned char *a: pointer to input byte array (of length KYBER_POLYCOMPRESSEDBYTES bytes)
**************************************************/
static void poly_unpack(poly *r, const unsigned char *a)
{
  int i;
#if (KYBER_POLYCOMPRESSEDBYTES == 96)
  for(i=0;i<KYBER_N;i+=8)
  {
    r->coeffs[i+0] =  (((a[0] & 7)));
    r->coeffs[i+1] = ((((a[0] >> 3) & 7)));
    r->coeffs[i+2] = ((((a[0] >> 6) | ((a[1] << 2) & 4))));
    r->coeffs[i+3] = ((((a[1] >> 1) & 7)));
    r->coeffs[i+4] = ((((a[1] >> 4) & 7)));
    r->coeffs[i+5] = ((((a[1] >> 7) | ((a[2] << 1) & 6))));
    r->coeffs[i+6] = ((((a[2] >> 2) & 7)));
    r->coeffs[i+7] = ((((a[2] >> 5))));
    a += 3;
  }
#elif (KYBER_POLYCOMPRESSEDBYTES == 128)
  for(i=0;i<KYBER_N;i+=8)
  {
    r->coeffs[i+0] = (((a[0] & 15)));
    r->coeffs[i+1] = (((a[0] >> 4)));
    r->coeffs[i+2] = (((a[1] & 15)));
    r->coeffs[i+3] = (((a[1] >> 4)));
    r->coeffs[i+4] = (((a[2] & 15)));
    r->coeffs[i+5] = (((a[2] >> 4)));
    r->coeffs[i+6] = (((a[3] & 15)));
    r->coeffs[i+7] = (((a[3] >> 4)));
    a += 4;
  }
#elif (KYBER_POLYCOMPRESSEDBYTES == 160)
  for(i=0;i<KYBER_N;i+=8)
  {
    r->coeffs[i+0] =  (((a[0] & 31)));
    r->coeffs[i+1] = ((((a[0] >> 5) | ((a[1] & 3) << 3))));
    r->coeffs[i+2] = ((((a[1] >> 2) & 31)));
    r->coeffs[i+3] = ((((a[1] >> 7) | ((a[2] & 15) << 1))));
    r->coeffs[i+4] = ((((a[2] >> 4) | ((a[3] &  1) << 4))));
    r->coeffs[i+5] = ((((a[3] >> 1) & 31)));
    r->coeffs[i+6] = ((((a[3] >> 6) | ((a[4] &  7) << 2))));
    r->coeffs[i+7] =  (((a[4] >> 3)));
    a += 5;
  }
#else
#error "KYBER_POLYCOMPRESSEDBYTES needs to be in {96, 128, 160}"
#endif
}

static void polycompare(masked_u32 *w, masked_u32 *x, const masked_poly *ru, const poly *u, size_t offset, const int16_t *S, size_t S_length) 
{
  size_t i, n;
  int16_t su, eu;
  masked_coeff_q wq;
  masked_coeff_pow2 w2, x2;
  for (i = 0; i < 32; i++)
  {
    // look up start and end point
    su = S[u->coeffs[offset+i]];
    eu = S[(u->coeffs[offset+i]+1)%S_length];
    
    for (n = 0; n < MASKING_N; n++)
    {
      wq.i16[n] = ru->polys[n].coeffs[offset+i];
    }
    w2 = transformpower2(wq);
    for (n = 0; n < MASKING_N; n++)
    {
      x2.i16[n] = w2.i16[n];
    }
    w2.i16[0] = w2.i16[0] + (1<<11) - su; 
    x2.i16[0] = x2.i16[0] - eu;
    
    
#ifdef COMPARE_USE_A2A
    for (n = 0; n < MASKING_N; n++)
    {
      x2.i16[n] <<= 1; // shift left so we can use use A2A with k*n=12
      w2.i16[n] <<= 1;
    }
#endif

    
#if MASKING_N == 2
#ifdef COMPARE_USE_A2A
    A2A_C_A_13_1(&x2.i16[0], &x2.i16[1]);
    A2A_C_A_13_1(&w2.i16[0], &w2.i16[1]);
#else
    x2.i16[0] = A2B_convert(x2.i16[0], x2.i16[1]);
    w2.i16[0] = A2B_convert(w2.i16[0], w2.i16[1]);
#endif
#else
#error "A2B conversion requires MASKING_N=2"
#endif
    
    
    for (n = 0; n < MASKING_N; n++)
    {
      w->u32[n] <<= 1;
      x->u32[n] <<= 1;
#ifdef COMPARE_USE_A2A
      w->u32[n] |= w2.i16[n] & 1;
      x->u32[n] |= x2.i16[n] & 1;
#else
      w->u32[n] |= (w2.i16[n] >> 11) & 1;
      x->u32[n] |= (x2.i16[n] >> 11) & 1;
#endif
    }
  }
}

uint8_t masked_decompressed_ct_cmp( const uint8_t *ct, const masked_polyvec *ru, const masked_poly *rv)
{
  size_t i, j;
  uint32_t res;
  poly uv;
  masked_u32 tw = {.u32={0}}, tx = {.u32={0}}, r = {.u32 = {0}};
  r.u32[0] = 0xffffffff;
  
#ifdef COMPARE_USE_A2A
  A2A_reset();
#endif
  
  // compare polyvec u
  for (i = 0; i < KYBER_K; i++)
  {
    polyvec_poly_unpack(&uv, ct, i);
    for (j = 0; j < KYBER_N; j += 32)
    {
      polycompare(&tw, &tx, &ru->vec[i], &uv, j, S10, 1<<10);
      r = secand(r, secand(tw, tx));
    }
  }
  
  // compare poly v
  poly_unpack(&uv, ct + KYBER_POLYVECCOMPRESSEDBYTES);
  for (j = 0; j < KYBER_N; j += 32)
  {
    polycompare(&tw, &tx, rv, &uv, j, S4, 1<<4);
    r = secand(r, secand(tw, tx));
  }
  
  // unmask r
  res = r.u32[0];
  for (i = 1; i < MASKING_N; i++)
  {
    res ^= r.u32[i];
  }
  
  // compress result to 1 bit
  res &= res >> 16;
  res &= res >> 8;
  res &= res >> 4;
  res &= res >> 2;  
  res &= res >> 1;
  return !res; // 0 indicates equality
}
